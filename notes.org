#+OPTIONS: toc:nil

* To-Do
- [ ] Get this org file to export the README section every time it's saved.
- [X] Get unit tests running inside Emacs.
- [X] Get gorename tool working (again, inside of Emacs)

* Readme
A collection of tools for the [[http://nand2tetris.org/][Nand2Tetris project.]]

** Components
Everything needed for a basic assembler and compiler.  A Lexer (assembly -> tokens), parser (tokens -> machine code) and a compiler (watch this space, will have own lexer/parser).

I'm going with a fully fledged lexer/parser for the initial Assembler project so that it can be reused in the compiler project.  The Lexer is blatantly ripped from [[https://www.youtube.com/watch?v=HxaD_trXwRE][Rob Pike's talk here]].

It's totally overkill for the assembler, (which is really just an exercise in substitution, and would be easy enough to do with regular expressions (eugh)), but I figure this will be more challenging and a good way to get my head around Go (plus partial reuse in the compiler project).

** Assembler
Basic assembler that maps symbols/tokens to machine instructions.  Output is a text file with "binary" values written out as string.  Internally they're all going to be represented by 16 bit constants that are then OR'd together and converted to a string representation at the end.  This is because it sounds more 'program-y' but mainly because I cannot bring myself to write this using string concatenation (plus it's good practice as I'm learning Go at the same time).

** Compiler
TBD

* Golang notes
** Allocation
 - new() :: creates new instance, zeros it, and /returns a pointer./ 
 - make() :: creates new instance, zeros it and /returns the thing itself./  Used for maps, slices and channels *only*:

#+BEGIN_SRC go
  p := new(chan int)   // p has type: *chan int
  c := make(chan int)  // c has type: chan int
#+END_SRC

Also, note that slices maps & channels, are /reference types/, with implicit pointers and aliasing (think objects in Delphi, ahhh those were the days).  i.e. a slice is three words that get passed on the stack, and one of them is a reference to the underling array.

So, given the following struct:

#+BEGIN_SRC go
  type SymbolTable struct {
    variables map[string]int
    labels    map[string]int
  }

  fred := SymbolTable{}
  test := fred.values == nil   // TRUE

  ethel := SymbolTable {
    variables: make(map[string]int),
    labels: make(map[string]int)}

  test2 := ethel.values == nil  // FALSE
#+END_SRC

Note that there's no real need to use new.  Instead, use a literal preceded by an '&':

#+BEGIN_SRC go
  fred := &SymbolTable{}
#+END_SRC

A pointer to a struct will automatically be dereferenced:

#+BEGIN_SRC go
  type test struct {
    name string
  }

  fred := test{ name: "Fred" }
  ethel = &fred

  fmt.Printf("No dereferencing required: %s", ethel.name) // "...: Fred"
#+END_SRC

** Godoc
*** Writing
Any comments found immediately before the declaration of a type, variable, constant, function or package, with no intervening blank lines, will extracted.

By convention, make the first word the name of whatever it is that you're documenting, as it will be used as a header:

#+BEGIN_SRC go
  // Myfunc does "stuff"....
  func MyFunc()
#+END_SRC

the above will result in a header "func MyFunc" (in that nice shade of blue that the go team seems to like so much).

Comments elsewhere are ignored, with the exception of ~// BUG(name)~ 
which will be extracted into the bugs section of the documentation.

URLS - these are converted to links, no markup required.

Pre-formatted text must be indented relative to the surrounding text:

#+BEGIN_SRC go
// Blah blah
//   this will be treated a preformatted text
// More blah blah...
#+END_SRC

Headers - use something like the following:

#+BEGIN_SRC go
  /* Blah blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble.

  Some title

  Blah blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble blah thing wobble */
#+END_SRC

That's pretty much it.
*** Running as a server
godoc -http=:6060

Will extract docs from GOROOT etc as far as I can tell, because it also displays any documentation that I apply to public types/functions etc.  This is cool.....

*** Querying
If invoked with the -q option, (and -server is not specified) godoc will first try loclhost:6060, and then godoc.org.

*** Generation
Godoc seems to take it straight from the source/package itself, so erm, no generation required?  Index may take a while to build though.  Need to play around with it some more, tis is seriously cool and /very/ well thought out.

*** Example functions

This is awesome!  The following code:

#+BEGIN_SRC go
  func ExampleMyFunc() {
    fmt.Println(MyFunc(some, params))
  }
#+END_SRC

will generate example code in the docs that users can both edit and run.  Note: must start with 'Example' and take no parameters.

** Unit tests
Create in the same folder as the package code, with the same name as the file you're writing tests for, with ~_test~ appended to the end of it.  Make sure that it has the same package name.  Tests will not be included in the executable.

In that file, import "testing", and create fun functions like:

#+BEGIN_SRC go
  package packageName

  import "testing"

  func TestAverage(t *testing.T) { // note the use of camel case!
    // get some result...
    if result != expected {
      t.Error("Expected 3.141, but ", badResult)
    }
  }
#+END_SRC

So no assertions etc, no fluent interfaces.  Although fluent interfaces are a symptom of OO code, so yay, no OO!  Also, testing.T would make sooooooo many C# devs lose their shit.  I mustn't like this language because it would offend enterprise-level purists.....  Shouldn't I?

The ~go test~ command will look for all functions starting with ~Test~ (pascal case FTW) and taking an argument of ~*testing.T~, and run them.  

And that, is pretty much it.
* Lexer (Assembler)

  - [X] Wrapper around a hash table for the symbol table.  Don't worry about where stuff is located for now, just one file.
  - [X] Look into Go best practices for organising packages, and reorganise :-)
  - [X] finish lexer
  - [X] Find out how the documentation package works, so can document code accordingly
  - [X] Read up on tests and write some for symbol table - can I get these running from Emacs?  Make one deliberately fail, just to be sure :-)
  - [X] Work out if everything that I've made public actually needs to be.  i.e. AsmInstruct isn't useful if you're just making an assembler, giving it a text file and expecting instructions back.  Get gorename working in Emacs for this.
  - [X] tests for lexer - known input should produce same stream of tokens.
  - [X] go through the names.  Kinda not great, plus prob over complicating things
  - [X] Take notes on Lexing vs parsing: [[https://en.wikipedia.org/wiki/Lexical_analysis][here]], [[https://en.wikipedia.org/wiki/Parsing][here]], [[http://www.perl.com/pub/2012/10/an-overview-of-lexing-and-parsing.html][here]]  /FOCUS ON THE LEXER!/  Only read enough on parsing to know where the responsibility lies, /don't/ start learning them yet, as wont be needed until the Compiler project.  For the assembler I can just wing it.
  - [X] Rename Lexine to lexeme
  - [X] Simple front-end to lexer to take input, and spit out lexenes to std out or specified file
  - [X] Add an error Lexeme
  - [X] Delete acceptUntil
  - [X] Make an "accept" method
  - [X] Add constants to specify valid symbol names, instructions etc
  - [X] update existing state functions to use accept
  - [X] tests!
  - [X] remind self that this is a functional(ish) state machine; in other words, should think of each state function as knowing only a) what it's expected to emit (including errors) and b) what states it can then hand off the work to.  I've been trying to think of them as working all together, which they do, but that leads to expecting side effects from other states and predicting what's happened before.  Each state should assume that it's at the exact place it needs to be to start work, and have zero expectations of what's already happened.
  - [X] Add in EOL lexeme
  - [X] Add linenumber to lexeme
  - [X] Write a peek function
  - [X] errorState - an error has been detected, emit error, skip to past EOL (or EOF) and return skipWhitespace
  - [X] When finished dest, if next char is anything but = or ;, emit en error, and return errorState
  - [X] FOr all existing state functions, if they run accept() and come up empty, emit error and retrun errorState
  - [X] When finished comp, if next char is anything but ; or a space, emit an error and return errorState
  - [ ] lookForEol - skips whitespace, if find comment will skip to eol, otherwise emit error and return errroState
  - [ ] When finished jmp, emit and return lookForEol
  - [ ] When finished aInstruction, return lookForEol
  - [ ] When finished symbol, return lookForEol
  - [ ] both lookForEol and errorState should increment currentLineNumber 
  - [ ] Update tests!
  - [ ] Track current line number
  - [ ] Add line number to errors, move the emiting of an error into a warpper function that takes a line number, emites an error, and then returns the errorState function
  - [ ] Determine if can skip over comments without using the rewind to method.  Could just save pos locally and then set it back?
* Parser (Assembler)
TBD


